#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#include "mix_g_types.h"
#include "constants.h"

/**********************************************************************
 * Save frame to rgb ppm file
 *********************************************************************/
void save_frame_rgb(unsigned char frame[HEIGHT*WIDTH*3], int width, int height,
                    char base[], int iFrame) {

  FILE *pFile;
  char filename[32];
  int y;

  sprintf(filename, "%s%d.ppm", base, iFrame);
  pFile=fopen(filename, "wb");
  if(pFile == NULL)
    return;

  fprintf(pFile, "P6\n%d %d\n255\n", width, height);
  //for(y=0; y<height; y++)
  fwrite(frame, 1, height*width*3, pFile);

  fclose(pFile);
}

void save_frame_g(unsigned char frame[HEIGHT*WIDTH*3], int width, int height,
                  char base[], int iFrame) {

  FILE *pFile;
  char filename[32];
  int y, grayval;

  sprintf(filename, "%s%d.pgm", base, iFrame);
  pFile=fopen(filename, "wb");
  if(pFile == NULL)
    return;

  fprintf(pFile, "P5\n%d %d\n255\n", width, height);
  for(y=0; y<height*width*3; y+=3) {
    grayval = (int) ((double)frame[y]*0.21+
                     (double)frame[y+1]*.71+
                     (double)frame[y+2]*.07);
    putc(grayval, pFile);
  }    

  fclose(pFile);
}


/***************************************************
 * Process video into images
 **************************************************/
int main(int argc, char *argv[]) {

  int frame_idx = 0;
  unsigned char frame[HEIGHT*WIDTH*3];
  char *filename = argv[1];
  char *fileBase = argv[2];

  AVFormatContext *pFormatCtx;
  int             i, videoStream;
  AVCodecContext  *pCodecCtx;
  AVCodec         *pCodec;
  AVFrame         *pFrame;
  AVFrame         *pFrameRGB;
  AVPacket        packet;
  int             frameFinished;
  int             numBytes;
  uint8_t         *buffer;
  
  static struct SwsContext *img_convert_ctx;

  fprintf(stderr, "Processing %s to ppm image files.\n", filename);

  // initialize all codecs
  av_register_all();
  
  // Open input video file
  if(av_open_input_file(&pFormatCtx, filename, NULL, 0, NULL) !=0) { 
    fprintf(stderr, "Could not open input file.\n");
    return -1;
  }

  printf("Opened %s for reading.\n", filename);

  if(av_find_stream_info(pFormatCtx)<0) {
    fprintf(stderr, "Could not find video stream.\n");
      return -1;
  }

  printf("Found videostream info.\n");

  dump_format(pFormatCtx, 0, filename, false);
  // Find the first video stream
  videoStream = -1;
  for(i=0; i<pFormatCtx->nb_streams; i++) {
    if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO) {
      videoStream = i;
      break;
    }
  }
  
  if(videoStream == -1) {
    fprintf(stderr,"videostream == -1\n");
    return -1;
  }
  
  // Get a pointer to the codec context for the video stream
  pCodecCtx = pFormatCtx->streams[videoStream]->codec;
  
  // Find the decoder for the video stream
  pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
  if(pCodec == NULL) {
    fprintf(stderr,"Could not find a suitable decoder.\n");
    return -1;
  }

  // Open codec
  if(avcodec_open(pCodecCtx, pCodec)<0) {
    fprintf(stderr,"Could not open codec.\n");
    return -1; // Could not open codec                             
  }  
  
  // Correct wrong frame rates that seem to be generated by some codecs
  if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
    pCodecCtx->time_base.den=1000;
  
  // Allocate video frame
  pFrame=avcodec_alloc_frame();  

  // Allocate an AVFrame structure
  pFrameRGB=avcodec_alloc_frame();
  if(pFrameRGB==NULL) {
    printf("Could not allocate AVFrame structure.\n");
    return -1;
  }

  fprintf(stderr, "Allocated structure.\n");
  
  // Determine required buffer size and allocate buffer   
  numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,
                              pCodecCtx->height);
  
  buffer=malloc(numBytes);
  
  fprintf(stderr, "Allocated buffer.\n");

  // Assign appropriate parts of buffer to image planes in pFrameRGB   
  avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24,
                 pCodecCtx->width, pCodecCtx->height);
  

  // Decode frames
  while(av_read_frame(pFormatCtx, &packet)>=0) {
    if(packet.stream_index==videoStream) {

      avcodec_decode_video(pCodecCtx, pFrame, &frameFinished,
                           packet.data, packet.size);

      fprintf(stderr, "Decoding frame %d.\n", frame_idx);
 
      if(!img_convert_ctx) {
        img_convert_ctx = sws_getContext(WIDTH,HEIGHT, 
                                         pCodecCtx->pix_fmt,
                                         WIDTH, HEIGHT,
                                         PIX_FMT_RGB24,
                                         SWS_BILINEAR, 
                                         NULL, NULL, NULL);
        
      }

      //fprintf(stderr, "About to scale image.\n");

      sws_scale(img_convert_ctx, (const uint8_t* const *)pFrame->data, 
                pFrame->linesize,0, HEIGHT, 
                pFrameRGB->data, pFrameRGB->linesize);
      
      //fprintf(stderr, "Scaled image\n");

      if(frameFinished) {
        memcpy(frame, pFrameRGB->data[0], WIDTH*HEIGHT*3);
        save_frame_rgb(frame, WIDTH, HEIGHT,fileBase, frame_idx);
        save_frame_g(frame, WIDTH, HEIGHT, fileBase, frame_idx);
        fprintf(stderr, "Frame %d finished\n", frame_idx);
        frame_idx++;
      }
    }
  }

  // Free the RGB image                             
  free(buffer);
  av_free(pFrameRGB);
  
  // Free the YUV frame
  av_free(pFrame);
  
  // Close the codec                     
  avcodec_close(pCodecCtx);
  
  // Close the video file                                   
  av_close_input_file(pFormatCtx);

  return 0;
}
